# ðŸ§  Clustering Module

This module implements the citation network clustering pipeline. The current approach uses a physics-based layout (ForceAtlas2) and a variable-density clustering algorithm (HDBSCAN) to identify research communities. This method is GPU-accelerated using RAPIDS cuGraph and cuML.

## ðŸ“‚ Directory Structure

```
src/clustering/
â”œâ”€â”€ ðŸš€ Current Pipeline (ForceAtlas2 + HDBSCAN)
â”‚   â”œâ”€â”€ physics_clustering_migration.py # Main script to run the new pipeline and update the DB
â”‚   â”œâ”€â”€ gpu_physics_clustering.py       # Core logic for GPU-accelerated ForceAtlas2
â”‚   â””â”€â”€ data_loader.py                  # Database I/O utilities (shared)
â”‚
â”œâ”€â”€  legacy_node2vec/                  # Old pipeline (Node2Vec + UMAP + KMeans)
â”‚   â”œâ”€â”€ pipeline.py                     # Main orchestration script for the old pipeline
â”‚   â”œâ”€â”€ embeddings.py                   # Node2vec embedding generation
â”‚   â”œâ”€â”€ dimensionality_reduction.py     # UMAP/t-SNE 2D projection
â”‚   â”œâ”€â”€ clustering.py                   # K-means with elbow method
â”‚   â””â”€â”€ ... (cached .npy files)         # Old cached results
â”‚
â”œâ”€â”€ ðŸ”Ž Cluster Analysis & Naming
â”‚   â”œâ”€â”€ CLUSTER_NAMING_SYSTEM.md        # Documentation on the cluster naming process
â”‚   â”œâ”€â”€ cluster_theme_extractor.py      # Extracts themes from clusters
â”‚   â”œâ”€â”€ cluster_api_integration.py      # Integrates themes with the API
â”‚   â””â”€â”€ ... (JSON cache files)          # Cached cluster names and themes
â”‚
â”œâ”€â”€ ðŸ› ï¸ utils/                           # Utility & Debug Scripts
â”‚   â”œâ”€â”€ prepare_database.py             # Database setup & verification
â”‚   â”œâ”€â”€ check_progress.py               # Monitor pipeline progress
â”‚   â””â”€â”€ monitor_gpu.py                  # Real-time GPU monitoring
â”‚
â”œâ”€â”€ ðŸ’¾ cache/                           # General-purpose cache
â”‚
â”œâ”€â”€ ðŸ“Š logs/                            # Execution Logs
â”‚
â””â”€â”€ ðŸ“– Documentation
    â”œâ”€â”€ README.md                       # This file
    â””â”€â”€ GPU_PHYSICS_CLUSTERING_GUIDE.md # Guide for the new GPU pipeline
```

## ðŸš€ Quick Start

To run the latest clustering pipeline and update the `physics_clustering` table in the database:

```bash
cd src/clustering
python physics_clustering_migration.py
```

To compare the results of the new pipeline with the old one:
```bash
python physics_clustering_migration.py --compare
```

## ðŸ“ˆ Key Features

### âš¡ GPU Acceleration (RAPIDS)
- **cuGraph ForceAtlas2**: Massively parallel graph layout algorithm.
- **cuML HDBSCAN**: GPU-accelerated hierarchical clustering that excels at variable-density data.
- **Full Pipeline Speed**: Processes >70k papers and >400k citation edges in **under 10 seconds** on an NVIDIA A100. This is a ~360x speedup over the previous CPU-based pipeline which took ~60 minutes.

### ðŸ”¬ High-Quality Physics-Based Clustering
- **ForceAtlas2 Layout**: Simulates physical forces (attraction/repulsion) to arrange nodes. Its `lin_log` mode is particularly effective at revealing community structures in citation networks.
- **HDBSCAN for Variable Density**: Unlike KMeans or DBSCAN which struggle with the structure of citation graphs (one super-dense core, many sparse communities), HDBSCAN can identify clusters of varying shapes and densities, which is a perfect match for this data. It also correctly identifies "noise" points that don't belong to any cluster.

## ðŸ“Š Current Results

**Latest Pipeline Run (ForceAtlas2 + HDBSCAN):**
- âœ… **72,493 papers** processed
- âœ… **~100 meaningful clusters** identified
- âœ… **~27,000 papers** correctly identified as noise (weakly connected nodes, expected for this type of network)
- âœ… **Largest cluster** contains ~18k papers, representing a major subfield.
- âœ… **Intra-cluster citation density** is significantly improved over the old method, indicating more cohesive communities.

## ðŸ”§ Troubleshooting

### GPU Issues
```bash
# Verify RAPIDS installation and see GPU
python -c "import cudf; print(cudf.DataFrame())"

# Monitor GPU usage during a run
watch -n 0.5 nvidia-smi
```

### Database Issues
```bash
# Prepare/verify database schema
python utils/prepare_database.py

# Check processing progress (if you add logging to the migration script)
tail -f logs/migration.log
```

## ðŸ“‹ Dependencies

### Core Requirements
- `numpy`, `pandas`, `scikit-learn`, `igraph`

### GPU Requirements (RAPIDS)
- `cuml`, `cupy`, `cudf`, `cugraph`
- NVIDIA GPU with CUDA 11.2+

## ðŸ“š Technical Details

For a deep dive into the implementation and the rationale behind choosing ForceAtlas2 and HDBSCAN, see the [GPU Physics Clustering Guide](GPU_PHYSICS_CLUSTERING_GUIDE.md). 
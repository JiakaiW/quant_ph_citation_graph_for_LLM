{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total quant-ph papers: 163070\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "def get_quantph_total():\n",
    "    url = \"http://export.arxiv.org/api/query\"\n",
    "    params = {\n",
    "        \"search_query\": \"cat:quant-ph\",\n",
    "        \"start\": 0,\n",
    "        \"max_results\": 0  # only return metadata, not entries\n",
    "    }\n",
    "    resp = requests.get(url, params=params)\n",
    "    root = ET.fromstring(resp.content)\n",
    "    ns = {'arxiv': 'http://a9.com/-/spec/opensearch/1.1/'}\n",
    "    total_results = root.find('arxiv:totalResults', ns)\n",
    "    return int(total_results.text)\n",
    "\n",
    "total = get_quantph_total()\n",
    "print(f\"Total quant-ph papers: {total}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching arXiv IDs: 100%|██████████| 1631/1631 [17:32<00:00,  1.55it/s]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import sqlite3\n",
    "import time\n",
    "from typing import Dict, List, Tuple\n",
    "from tqdm import tqdm\n",
    "DB_PATH = \"arxiv_citation.db\"\n",
    "NUM_PAPERS = 163070\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 1: Fetch arXiv IDs\n",
    "# -------------------------------\n",
    "def fetch_arxiv_ids(max_results: int) -> List[str]:\n",
    "    base_url = \"http://export.arxiv.org/api/query\"\n",
    "    ids = []\n",
    "    for start in tqdm(range(0, max_results, 100),desc=\"Fetching arXiv IDs\"):\n",
    "        params = {\n",
    "            \"search_query\": f\"cat:quant-ph\",\n",
    "            \"start\": start,\n",
    "            \"max_results\": 100,\n",
    "            \"sortBy\": \"submittedDate\",\n",
    "            \"sortOrder\": \"descending\",\n",
    "        }\n",
    "        resp = requests.get(base_url, params=params)\n",
    "        entries = resp.text.split(\"<entry>\")\n",
    "        for entry in entries[1:]:\n",
    "            try:\n",
    "                id_line = next(line for line in entry.split(\"\\n\") if \"<id>\" in line)\n",
    "                url = id_line.strip().replace(\"<id>\", \"\").replace(\"</id>\", \"\")\n",
    "                arxiv_id = url.split(\"/\")[-1]\n",
    "                ids.append(arxiv_id)\n",
    "            except StopIteration:\n",
    "                continue\n",
    "        if len(ids) >= max_results:\n",
    "            break\n",
    "    return ids\n",
    "\n",
    "arxiv_ids = fetch_arxiv_ids( NUM_PAPERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# STEP 2: Fetch Metadata + Citations from Semantic Scholar\n",
    "# -------------------------------\n",
    "def fetch_citation_edges(arxiv_ids: List[str]) -> Tuple[Dict[str, dict], List[Tuple[str, str]]]:\n",
    "    edges = []\n",
    "    paper_data = {}\n",
    "    headers = {\"User-Agent\": \"qubit-citation-crawler\"}\n",
    "\n",
    "    for arxiv_id in arxiv_ids:\n",
    "        s2_url = f\"https://api.semanticscholar.org/graph/v1/paper/arXiv:{arxiv_id}?fields=title,year,references.paperId\"\n",
    "        try:\n",
    "            resp = requests.get(s2_url, headers=headers)\n",
    "            if resp.status_code != 200:\n",
    "                continue\n",
    "            data = resp.json()\n",
    "            paper_data[data['paperId']] = {\n",
    "                \"arxiv_id\": arxiv_id,\n",
    "                \"title\": data.get(\"title\", \"\"),\n",
    "                \"year\": data.get(\"year\", None)\n",
    "            }\n",
    "            refs = data.get(\"references\", [])\n",
    "            for ref in refs:\n",
    "                ref_id = ref.get(\"paperId\")\n",
    "                if ref_id:\n",
    "                    edges.append((data['paperId'], ref_id))\n",
    "            time.sleep(1)  # to respect API rate limits\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {arxiv_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return paper_data, edges\n",
    "\n",
    "print(\"Fetching metadata and references from Semantic Scholar...\")\n",
    "paper_data, edges = fetch_citation_edges(arxiv_ids)\n",
    "print(f\"Fetched metadata for {len(paper_data)} papers and {len(edges)} citation edges.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_url = f\"https://api.semanticscholar.org/graph/v1/paper/arXiv:{arxiv_ids[3]}?fields=title,year,references.paperId\"\n",
    "resp = requests.get(s2_url, headers={\"User-Agent\": \"qubit-citation-crawler\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Response [429]>, 429)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp, resp.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Too Many Requests. Please wait and try again or apply for a key for higher rate limits. https://www.semanticscholar.org/product/api#api-key-form',\n",
       " 'code': '429'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = resp.json()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "paper_data[data['paperId']] = {\n",
    "    \"arxiv_id\": arxiv_ids[3],\n",
    "    \"title\": data.get(\"title\", \"\"),\n",
    "    \"year\": data.get(\"year\", None)\n",
    "}\n",
    "refs = data.get(\"references\", [])\n",
    "for ref in refs:\n",
    "    ref_id = ref.get(\"paperId\")\n",
    "    if ref_id:\n",
    "        edges.append((data['paperId'], ref_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# STEP 3: Store in SQLite\n",
    "# -------------------------------\n",
    "def create_db(db_path: str = DB_PATH):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS papers (\n",
    "            paper_id TEXT PRIMARY KEY,\n",
    "            arxiv_id TEXT,\n",
    "            title TEXT,\n",
    "            year INTEGER\n",
    "        )\n",
    "    \"\"\")\n",
    "    c.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS citations (\n",
    "            source_id TEXT,\n",
    "            target_id TEXT,\n",
    "            PRIMARY KEY (source_id, target_id)\n",
    "        )\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    return conn\n",
    "\n",
    "def insert_data(conn, paper_data: Dict[str, dict], edges: List[Tuple[str, str]]):\n",
    "    c = conn.cursor()\n",
    "    for pid, meta in paper_data.items():\n",
    "        c.execute(\"INSERT OR IGNORE INTO papers VALUES (?, ?, ?, ?)\",\n",
    "                  (pid, meta.get(\"arxiv_id\", \"\"), meta[\"title\"], meta[\"year\"]))\n",
    "    for src, tgt in edges:\n",
    "        c.execute(\"INSERT OR IGNORE INTO citations VALUES (?, ?)\", (src, tgt))\n",
    "    conn.commit()\n",
    "\n",
    "print(\"Saving to SQLite database...\")\n",
    "conn = create_db()\n",
    "insert_data(conn, paper_data, edges)\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
